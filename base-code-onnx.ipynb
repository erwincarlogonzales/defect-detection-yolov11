{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics supervision roboflow mlflow python-dotenv matplotlib seaborn --quiet\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import mlflow\n",
    "from typing import Dict, Union\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image as IPyImage, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "# Set up MLflow credentials using Colab secrets\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# User defined inputs\n",
    "MLFLOW_TRACKING_URI = 'https://dagshub.com/erwincarlogonzales/defect-detection-yolov11.mlflow'\n",
    "EXPERIMENT_NAME = 'defect-detection-yolov11s-jetson'\n",
    "\n",
    "# Get credentials and set environment variables\n",
    "try:\n",
    "    os.environ.update({\n",
    "        'MLFLOW_TRACKING_URI': MLFLOW_TRACKING_URI,\n",
    "        'MLFLOW_TRACKING_USERNAME': userdata.get('MLFLOW_TRACKING_USERNAME'),\n",
    "        'MLFLOW_TRACKING_PASSWORD': userdata.get('MLFLOW_TRACKING_PASSWORD')\n",
    "    })\n",
    "\n",
    "    # Verify MLflow connection\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"Successfully connected to MLflow {MLFLOW_TRACKING_URI}\")\n",
    "    print(f\"Using experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "except Exception as error:\n",
    "    if 'userdata.get' in str(error):\n",
    "        raise Exception(f\"Failed to get secrets from Colab: {error}\")\n",
    "    raise ConnectionError(f'MLflow setup failed: {error}')\n",
    "\n",
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Configuration\n",
    "\n",
    "CONFIG = {\n",
    "    'dataset_url': 'https://app.roboflow.com/ds/JgwZ6J3BBV?key=Q4LLoOljfi',\n",
    "    'model_type': 'yolo11s.pt',\n",
    "    'epochs': 40,\n",
    "    'image_size': 640,\n",
    "    'conf_threshold': 0.50,\n",
    "    'patience': 3\n",
    "}\n",
    "\n",
    "def generate_model_name(config: Dict[str, Union[str, int, float]], separator: str = \"-\") -> str:\n",
    "\n",
    "# Validate epochs value\n",
    "    if not isinstance(config.get('epochs'), int) or config['epochs'] <= 0:\n",
    "        raise ValueError(\"epochs must be a positive integer\")\n",
    "\n",
    "    # Get model type from config, default to empty string\n",
    "    model_type = config.get('model_type', '')\n",
    "\n",
    "    # Validate model type\n",
    "    if not model_type or '.' not in model_type:\n",
    "        raise ValueError(\"model_type must be a non-empty string with a file extension\")\n",
    "\n",
    "    # Extract model type without extension\n",
    "    model_type = model_type.split('.')[0]\n",
    "\n",
    "    # Get confidence threshold from config, default to 0.25\n",
    "    conf_threshold = config.get('conf_threshold', 0.25)\n",
    "\n",
    "    # Convert confidence threshold to integer percentage\n",
    "    conf_value = str(int(conf_threshold * 100))  # Convert 0.25 to \"25\"\n",
    "\n",
    "    # Construct and return the model name\n",
    "    return f\"{model_type}{separator}{config['epochs']}{separator}{conf_value}\"\n",
    "\n",
    "# Set up working directory and dataset\n",
    "HOME = os.getcwd()\n",
    "print(f'Working Directory: {HOME}')\n",
    "\n",
    "# Create dataset directory\n",
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "# Download and extract Roboflow dataset\n",
    "%%time\n",
    "!curl -L '{CONFIG['dataset_url']}' > roboflow.zip 2>/dev/null\n",
    "!unzip -q roboflow.zip\n",
    "!rm roboflow.zip\n",
    "\n",
    "# Return to home directory\n",
    "%cd {HOME}\n",
    "\n",
    "# Visualization Functions\n",
    "def plot_confusion_matrix_heatmap(confusion_matrix, labels=['No Defect', 'Defect']):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "    heatmap_path = f'{HOME}/confusion_matrix_heatmap.png'\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    return heatmap_path\n",
    "\n",
    "def plot_training_metrics(results_file):\n",
    "    \n",
    "    # Load results from YOLO's CSV file\n",
    "    results = pd.read_csv(results_file)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    metrics_to_plot = {\n",
    "        'metrics/precision(B)': 'Precision',\n",
    "        'metrics/recall(B)': 'Recall',\n",
    "        'metrics/mAP50(B)': 'mAP@0.5',\n",
    "        'metrics/mAP50-95(B)': 'mAP@0.5:0.95'\n",
    "    }\n",
    "\n",
    "    for col, label in metrics_to_plot.items():\n",
    "\n",
    "        if col in results.columns:\n",
    "            plt.plot(results.index, results[col], label=label, marker='o')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Training Metrics Over Time')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    metrics_path = f'{HOME}/training_metrics.png'\n",
    "    plt.savefig(metrics_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics_path\n",
    "\n",
    "def extract_yolo_metrics(results_file):\n",
    "    \n",
    "    # Load results from the CSV file into a pandas DataFrame\n",
    "    results = pd.read_csv(results_file)\n",
    "\n",
    "    # Get the last row of the DataFrame, which represents the final epoch's results\n",
    "    final_epoch = results.iloc[-1]\n",
    "\n",
    "    # Create a dictionary to store the final metrics\n",
    "    # Access specific columns from the 'final_epoch' Series using column names\n",
    "    return {\n",
    "        'final_precision': final_epoch['metrics/precision(B)'],\n",
    "        'final_recall': final_epoch['metrics/recall(B)'],\n",
    "        'final_mAP50': final_epoch['metrics/mAP50(B)'],\n",
    "        'final_mAP50-95': final_epoch['metrics/mAP50-95(B)']\n",
    "    }\n",
    "    \n",
    "    # Helper functions\n",
    "def log_training_params(config):\n",
    "   \n",
    "    # Log key parameters to MLflow for tracking and reproducibility\n",
    "    mlflow.log_params({\n",
    "        'model_type': config['model_type'],         # The type of YOLO model used\n",
    "        'epochs': config['epochs'],                 # Number of training epochs\n",
    "        'image_size': config['image_size'],         # Image size used for training\n",
    "        'conf_threshold': config['conf_threshold']  # Confidence threshold for detections\n",
    "    })\n",
    "\n",
    "def train_yolo_model(config):\n",
    "  \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Disable MLflow callback before training to avoid conflicts\n",
    "    from ultralytics.utils.callbacks.mlflow import callbacks as mlflow_callbacks\n",
    "    mlflow_callbacks.clear()\n",
    "\n",
    "    # Start YOLO training using the command-line interface\n",
    "    !yolo task=detect mode=train \\\n",
    "        model={config['model_type']} \\\n",
    "        data=/content/datasets/data.yaml \\\n",
    "        epochs={config['epochs']} \\\n",
    "        imgsz={config['image_size']} \\\n",
    "        patience={config['patience']} \\\n",
    "        plots=True\n",
    "\n",
    "    return time.time() - start_time\n",
    "\n",
    "def get_latest_train_dir(home_dir):\n",
    "   \n",
    "    # Use glob to find all directories matching the pattern 'runs/detect/train*'\n",
    "    train_dirs = glob.glob(f'{home_dir}/runs/detect/train*')\n",
    "\n",
    "    # If no training directories are found, raise an exception\n",
    "    if not train_dirs:\n",
    "        raise FileNotFoundError(\"No training directories found\")\n",
    "\n",
    "    # Return the directory with the latest modification time\n",
    "    # (using os.path.getmtime as the key for the max function)\n",
    "    return max(train_dirs, key=os.path.getmtime)\n",
    "\n",
    "def process_confusion_matrix(home_dir):\n",
    "   \n",
    "    # Get the most recent training directory\n",
    "    latest_dir = get_latest_train_dir(home_dir)\n",
    "\n",
    "    # Construct the path to the confusion matrix file within the latest training directory\n",
    "    confusion_matrix_path = f'{latest_dir}/confusion_matrix.npy'\n",
    "\n",
    "    # Check if the confusion matrix file exists\n",
    "    if not os.path.exists(confusion_matrix_path):\n",
    "        print(f'WARNING: Confusion matrix not found at: {confusion_matrix_path}')\n",
    "        return None  # Return None if the file is not found\n",
    "\n",
    "    # Load the confusion matrix from the file\n",
    "    confusion_matrix = np.load(confusion_matrix_path)\n",
    "\n",
    "    # Create and log a heatmap visualization of the confusion matrix\n",
    "    heatmap_path = plot_confusion_matrix_heatmap(confusion_matrix)\n",
    "    mlflow.log_artifact(heatmap_path, 'visualizations')\n",
    "\n",
    "    # Calculate and log confusion matrix metrics (TP, TN, FP, FN)\n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()  # Flatten the matrix\n",
    "    metrics = {\n",
    "        'true_positives': tp,\n",
    "        'true_negatives': tn,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Return the confusion matrix\n",
    "    return confusion_matrix\n",
    "\n",
    "def process_training_metrics(home_dir):\n",
    "    \n",
    "    # Get the most recent training directory\n",
    "    latest_dir = get_latest_train_dir(home_dir)\n",
    "\n",
    "    # Construct the path to the results CSV file within the latest training directory\n",
    "    results_file = f'{latest_dir}/results.csv'\n",
    "\n",
    "    # Check if the results file exists\n",
    "    if not os.path.exists(results_file):\n",
    "        print(f'WARNING: Results file not found at: {results_file}')\n",
    "        return  # Return early if the file is not found\n",
    "\n",
    "    # Create and log a plot of the training metrics over time\n",
    "    metrics_path = plot_training_metrics(results_file)\n",
    "    mlflow.log_artifact(metrics_path, 'visualizations')\n",
    "\n",
    "    # Extract and log final YOLO metrics (precision, recall, mAP)\n",
    "    yolo_metrics = extract_yolo_metrics(results_file)\n",
    "    mlflow.log_metrics(yolo_metrics)\n",
    "\n",
    "def log_yolo_artifacts(home_dir):\n",
    " \n",
    "    # Get the most recent training directory\n",
    "    latest_dir = get_latest_train_dir(home_dir)\n",
    "    print(f\"Logging artifacts from: {latest_dir}\")\n",
    "\n",
    "    # Define a dictionary mapping artifact names to their file paths\n",
    "    artifact_paths = {\n",
    "        'confusion_matrix': f'{latest_dir}/confusion_matrix.png',\n",
    "        'results': f'{latest_dir}/results.png',\n",
    "        'validation_predictions': f'{latest_dir}/val_batch0_pred.jpg'\n",
    "    }\n",
    "\n",
    "    # Log each artifact to MLflow if it exists\n",
    "    logged_artifacts = 0  # Initialize a counter for logged artifacts\n",
    "\n",
    "    for name, path in artifact_paths.items():   # Iterate through the artifact paths\n",
    "        if os.path.exists(path):                # Check if the artifact file exists\n",
    "            mlflow.log_artifact(path, name)     # Log the artifact to MLflow\n",
    "            logged_artifacts += 1               # Increment the logged artifacts counter\n",
    "            print(f\"Successfully logged {name}\")  # Print a success message\n",
    "        else:\n",
    "            print(f'WARNING: Artifact not found: {path}')  # Print a warning if not found\n",
    "\n",
    "def display_training_results(width: int = 800, height=None, show_titles: bool = True):\n",
    "  \n",
    "    # Get the most recent training directory\n",
    "    latest_dir = get_latest_train_dir(HOME)\n",
    "    print(f\"Loading results from: {latest_dir}\")\n",
    "\n",
    "    # Define a dictionary mapping image titles to their file paths\n",
    "    results_config = {\n",
    "        'Confusion Matrix': f'{latest_dir}/confusion_matrix.png',\n",
    "        'Training Results': f'{latest_dir}/results.png',\n",
    "        'Validation Batch Predictions': f'{latest_dir}/val_batch0_pred.jpg'\n",
    "    }\n",
    "\n",
    "    # Check if each image file exists and store it in 'available_images' if it does\n",
    "    available_images = {}\n",
    "    for title, path in results_config.items():\n",
    "        if os.path.exists(path):\n",
    "            available_images[title] = path\n",
    "        else:\n",
    "            print(f\"Warning: {title} not found at {path}\")\n",
    "\n",
    "    # If no image files were found, print a message and return\n",
    "    if not available_images:\n",
    "        print(\"No result images found to display\")\n",
    "        return\n",
    "\n",
    "    # Create IPython Image objects for each available image\n",
    "    images = [IPyImage(filename=path, width=width, height=height)\n",
    "              for path in available_images.values()]\n",
    "\n",
    "    # Display the images with or without titles\n",
    "    if show_titles:\n",
    "        for title, image in zip(available_images.keys(), images):\n",
    "            print(f'\\n{title}')\n",
    "            display(image)\n",
    "    else:\n",
    "        display(*images)\n",
    "\n",
    "def display_predictions(num_images: int = 3, image_width: int = 600):\n",
    "  \n",
    "    # Find all prediction folders using glob, sorting by modification time to get the latest\n",
    "    prediction_folders = glob.glob('/content/runs/detect/predict*/')\n",
    "\n",
    "    # Check if any prediction folders were found\n",
    "    if not prediction_folders:\n",
    "        print(\"No prediction folders found. Ensure the prediction step ran successfully.\")\n",
    "        return  # Return early if no folders are found\n",
    "\n",
    "    # Get the most recent prediction folder based on modification time\n",
    "    latest_folder = max(prediction_folders, key=os.path.getmtime)\n",
    "\n",
    "    # Get a sorted list of prediction image paths within the latest folder\n",
    "    pred_images = sorted(glob.glob(f'{latest_folder}/*.jpg'))\n",
    "\n",
    "    # Print a heading indicating the number of predictions to be displayed\n",
    "    print(f'Top {num_images} Predictions:\\n')\n",
    "\n",
    "    # Display the specified number of prediction images\n",
    "    for img in pred_images[:num_images]:\n",
    "        display(IPyImage(filename=img, width=image_width))  # Display the image using IPython.display.Image\n",
    "        print('\\n')  # Add a newline for spacing between images.\n",
    "        \n",
    "# Train model with MLflow tracking\n",
    "%%time\n",
    "with mlflow.start_run(run_name=generate_model_name(CONFIG)) as run:  # Start a new MLflow run with a generated run name\n",
    "    try:\n",
    "        print(\"Starting training process...\")\n",
    "\n",
    "        # 1. Log training parameters to MLflow\n",
    "        log_training_params(CONFIG)\n",
    "        print(\"Parameters logged successfully\")\n",
    "\n",
    "        # 2. Train the YOLO model and log training time\n",
    "        print(\"Starting model training...\")\n",
    "        training_time = train_yolo_model(CONFIG)\n",
    "        mlflow.log_metric('training_time', training_time)\n",
    "        print(\"Training completed\")\n",
    "\n",
    "        # Give some time for files to be written (to avoid race conditions)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Save the best and last model files as MLflow artifacts\n",
    "        print(\"Saving model files...\")\n",
    "        latest_dir = get_latest_train_dir(HOME)\n",
    "        model_paths = {\n",
    "            'best_model': f'{latest_dir}/weights/best.pt',\n",
    "            'last_model': f'{latest_dir}/weights/last.pt'\n",
    "        }\n",
    "        for name, path in model_paths.items():\n",
    "            if os.path.exists(path):\n",
    "                mlflow.log_artifact(path, \"models\")\n",
    "                print(f\"Saved {name} successfully\")\n",
    "            else:\n",
    "                print(f'WARNING: Model file not found: {path}')\n",
    "\n",
    "        # Export and save ONNX model\n",
    "        print(\"Exporting to ONNX format...\")\n",
    "        model = YOLO(f'{latest_dir}/weights/best.pt')\n",
    "        model.export(format='onnx',\n",
    "                    opset=11,\n",
    "                    simplify=True,\n",
    "                    dynamic=True,\n",
    "                    half=False)\n",
    "\n",
    "        # Log ONNX model to MLflow\n",
    "        onnx_path = f'{latest_dir}/weights/best.onnx'\n",
    "        if os.path.exists(onnx_path):\n",
    "            mlflow.log_artifact(onnx_path, \"models\")\n",
    "            print(\"ONNX model saved and logged successfully\")\n",
    "        else:\n",
    "            print('WARNING: ONNX model file not found')\n",
    "\n",
    "        # 3. Process and log confusion matrix metrics\n",
    "        print(\"Processing confusion matrix...\")\n",
    "        confusion_matrix = process_confusion_matrix(HOME)\n",
    "\n",
    "        # 4. Process and log training metrics (from results.csv)\n",
    "        print(\"Processing training metrics...\")\n",
    "        process_training_metrics(HOME)\n",
    "\n",
    "        # 5. Log other YOLO artifacts (e.g., confusion matrix image, results plot)\n",
    "        print(\"Logging YOLO artifacts...\")\n",
    "        log_yolo_artifacts(HOME)\n",
    "\n",
    "        print('Training and logging completed successfully!')\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f'Error during training or logging: {str(error)}')\n",
    "        raise  # Re-raise the exception to stop execution and provide the error message\n",
    "    \n",
    "# Display training results function and execution\n",
    "display_training_results()\n",
    "\n",
    "# Validate model with MLflow tracking\n",
    "%%time\n",
    "with mlflow.start_run(run_id=run.info.run_id):  # Start a new MLflow run using the existing run ID\n",
    "\n",
    "    start_time = time.time()  # Record the start time for validation\n",
    "\n",
    "    !yolo task=detect mode=val \\\n",
    "        model={HOME}/runs/detect/train/weights/best.pt \\\n",
    "        data=/content/datasets/data.yaml\n",
    "\n",
    "    validation_time = time.time() - start_time  # Calculate the validation time\n",
    "\n",
    "    mlflow.log_metric('validation_time', validation_time)  # Log the validation time to MLflow\n",
    "    \n",
    "# Run predictions with MLflow tracking\n",
    "%%time\n",
    "with mlflow.start_run(run_id=run.info.run_id):  # Start a new MLflow run using the existing run ID\n",
    "\n",
    "    start_time = time.time()  # Record the start time for inference\n",
    "\n",
    "    # Run YOLO predictions using the command-line interface\n",
    "    !yolo task=detect mode=predict \\\n",
    "        model={HOME}/runs/detect/train/weights/best.pt \\\n",
    "        conf={CONFIG['conf_threshold']} \\\n",
    "        source=/content/datasets/test/images \\\n",
    "        save=True > /dev/null 2>&1\n",
    "\n",
    "    inference_time = time.time() - start_time  # Calculate the inference time\n",
    "\n",
    "    mlflow.log_metric('inference_time', inference_time)  # Log the inference time to MLflow\n",
    "\n",
    "print('Predictions completed!')  # Print a message indicating that predictions are finished\n",
    "\n",
    "# Display predictions\n",
    "display_predictions()\n",
    "\n",
    "# Register Model and Promote to Production\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def register_model_version(run_id: str, model_name: str):\n",
    "    \n",
    "    try:\n",
    "        # Construct the model URI using the run ID\n",
    "        model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "        # Register the model with MLflow.\n",
    "        model_details = mlflow.register_model(\n",
    "            model_uri=model_uri,\n",
    "            name=model_name\n",
    "        )\n",
    "\n",
    "        print(f'Model registered successfully with version: {model_details.version}')\n",
    "\n",
    "        # Optionally, add a description to the registered model\n",
    "        client = mlflow.MlflowClient()\n",
    "        client.update_registered_model(\n",
    "            name=model_name,\n",
    "            description='YOLO-based defect detection model'\n",
    "        )\n",
    "\n",
    "        return model_details  # Return the registered model details\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f'Error registering model: {str(error)}')\n",
    "\n",
    "        return None  # Return None if registration fails\n",
    "\n",
    "def promote_challenger_to_production(model_name: str, prod_name: str):\n",
    "   \n",
    "    try:\n",
    "        client = MlflowClient()  # Create an MLflow client\n",
    "\n",
    "        # Construct the URI for the challenger model\n",
    "        current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "\n",
    "        # Copy the challenger model version to the production model name.\n",
    "        production_model = client.copy_model_version(\n",
    "            src_model_uri=current_model_uri,\n",
    "            dst_name=prod_name\n",
    "        )\n",
    "\n",
    "        print(f'Successfully promoted challenger to Production as {prod_name}')\n",
    "\n",
    "        return production_model  # Return the production model details\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f'Error promoting model: {str(error)}')\n",
    "\n",
    "        return None  # Return None if promotion fails\n",
    "\n",
    "# Register Model Operation\n",
    "def register_model_operation(run_id: str, config: dict):\n",
    "   \n",
    "    model_name = generate_model_name(config)  # Generate the model name using the config\n",
    "\n",
    "    model_details = register_model_version(run_id, model_name)  # Register the model version\n",
    "\n",
    "    if model_details:  # Check if registration was successful\n",
    "        print('\\nModel Registration Details:')\n",
    "        print(f'Name: {model_details.name}')\n",
    "        print(f'Version: {model_details.version}')\n",
    "        print(f'Stage: {model_details.status}')\n",
    "\n",
    "        return model_details  # Return the model details if registration was successful\n",
    "\n",
    "    return None  # Return None if registration failed\n",
    "\n",
    "# Promote Challenger Model\n",
    "def promote_challenger_operation(model_name: str, prod_name: str = 'defect-detection-production'):\n",
    "    \n",
    "    production_model = promote_challenger_to_production(model_name, prod_name)  # Promote the model\n",
    "\n",
    "    if production_model:  # Check if promotion was successful\n",
    "        print(f'\\nProduction Model Details:')\n",
    "        print(f'Name: {production_model.name}')\n",
    "        print(f'Version: {production_model.version}')\n",
    "\n",
    "        return production_model  # Return the production model details if promotion was successful\n",
    "\n",
    "    return None  # Return None if promotion failed\n",
    "\n",
    "# Register Model\n",
    "run_id = 'run id from MLflow UI'  # Get the run ID from the MLflow UI\n",
    "model_details = register_model_operation(run_id, CONFIG)  # Register the model using the run ID and configuration\n",
    "\n",
    "# Promotion (after setting challenger alias in UI)\n",
    "if model_details:  # Proceed with promotion only if model registration was successful\n",
    "    prod_name = 'defect-detection-v11-android-production'  # Define the desired name for the production model\n",
    "    production_model = promote_challenger_operation(model_details.name, prod_name)  # Promote the challenger model to production"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
